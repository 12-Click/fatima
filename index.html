<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Image-Based AR Storytelling</title>
  <script src="https://aframe.io/releases/1.3.0/aframe.min.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js/aframe/build/aframe-ar-nft.js"></script>
</head>
<body style="margin: 0; overflow: hidden;">
  <!-- A-Frame Scene -->
  <a-scene embedded arjs="sourceType: webcam; trackingMethod: best; debugUIEnabled: false;" vr-mode-ui="enabled: false">
    
    <!-- NFT Tracking Setup for Image 1 -->
    <a-nft type="nft" url="nft/image1" smooth="true" smoothCount="10" smoothTolerance="0.01" smoothThreshold="5">
      <!-- Scenario 1: GLB Model with Text -->
      <a-entity gltf-model="url(./models/model1.glb)" position="0 0 0" scale="0.5 0.5 0.5" rotation="0 0 0" gesture-handler>
        <a-text value="This is model 1" position="0 2 0" color="#FFFFFF" scale="2 2 2"></a-text>
      </a-entity>
    </a-nft>

    <!-- NFT Tracking Setup for Image 2 -->
    <a-nft type="nft" url="nft/image2" smooth="true" smoothCount="10" smoothTolerance="0.01" smoothThreshold="5">
      <!-- Scenario 2: GLB Model with Video -->
      <a-entity gltf-model="url(./models/model2.glb)" position="0 0 0" scale="0.5 0.5 0.5" rotation="0 0 0" gesture-handler>
        <a-video src="#video1" width="4" height="2.5" position="0 1 0"></a-video>
      </a-entity>
    </a-nft>

    <!-- NFT Tracking Setup for Image 3 -->
    <a-nft type="nft" url="nft/image3" smooth="true" smoothCount="10" smoothTolerance="0.01" smoothThreshold="5">
      <!-- Scenario 3: Info Text with Rotation -->
      <a-entity rotation="0 0 0" gesture-handler>
        <a-text value="Story element 3: Rotatable" position="0 2 0" color="#FF0000" scale="2 2 2"></a-text>
      </a-entity>
    </a-nft>

    <!-- NFT Tracking Setup for Image 4 -->
    <a-nft type="nft" url="nft/image4" smooth="true" smoothCount="10" smoothTolerance="0.01" smoothThreshold="5">
      <!-- Scenario 4: Video Content -->
      <a-video src="#video2" width="5" height="3" position="0 1 0"></a-video>
      <a-text value="Scenario 4: Video playing" position="0 2 0" color="#FFFFFF" scale="2 2 2"></a-text>
    </a-nft>

    <!-- NFT Tracking Setup for Image 5 -->
    <a-nft type="nft" url="nft/image5" smooth="true" smoothCount="10" smoothTolerance="0.01" smoothThreshold="5">
      <!-- Scenario 5: Interactive Text Popup -->
      <a-entity rotation="0 0 0" gesture-handler>
        <a-text value="Tap to reveal more information" position="0 1 0" color="#00FF00" scale="1.5 1.5 1.5"></a-text>
      </a-entity>
    </a-nft>

    <!-- Camera for AR view -->
    <a-camera gps-camera rotation-reader></a-camera>

  </a-scene>

  <!-- Include video sources -->
  <video id="video1" loop autoplay>
    <source src="./videos/video1.mp4" type="video/mp4">
  </video>
  <video id="video2" loop autoplay>
    <source src="./videos/video2.mp4" type="video/mp4">
  </video>

  <!-- Gesture Handler Component for rotating and dragging -->
  <script>
    AFRAME.registerComponent('gesture-handler', {
      schema: {
        enabled: { default: true }
      },
      init: function () {
        var el = this.el;
        var isDragging = false;
        var startPos = { x: 0, y: 0 };

        el.addEventListener('mousedown', function (evt) {
          isDragging = true;
          startPos = { x: evt.clientX, y: evt.clientY };
        });

        window.addEventListener('mousemove', function (evt) {
          if (!isDragging) return;

          var deltaX = evt.clientX - startPos.x;
          var deltaY = evt.clientY - startPos.y;

          el.object3D.rotation.y += deltaX * 0.01;
          el.object3D.rotation.x += deltaY * 0.01;
          
          startPos = { x: evt.clientX, y: evt.clientY };
        });

        window.addEventListener('mouseup', function () {
          isDragging = false;
        });
      }
    });
  </script>
</body>
</html>
